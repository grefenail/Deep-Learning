{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a7b949d175fd35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T18:30:56.485707Z",
     "start_time": "2025-02-15T18:30:56.483549Z"
    }
   },
   "source": [
    "# Increase gpu memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77dedef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 13:51:47.437867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740228707.448585  567204 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740228707.451999  567204 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers.utils import logging\n",
    "\n",
    "# Limit GPU memory usage (e.g., 4GB)\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\"\n",
    "\n",
    "logging.set_verbosity_info()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f5abb",
   "metadata": {},
   "source": [
    "# Evaluate pretrained DETR on coco datatset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40228ac2",
   "metadata": {},
   "source": [
    "NOTE: GenAI tools were used for debugging and coding assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a00e1",
   "metadata": {},
   "source": [
    "Load Dataset (CoCo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b17d76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.56s)\n",
      "creating index...\n",
      "index created!\n",
      "Selected 1000 for evaluation\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from transformers import AutoImageProcessor, DetrForObjectDetection\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Define paths\n",
    "coco_root_dir = \"/home/utn/firi22ka/Desktop/jenga/mlp/g10/datasets\"\n",
    "coco_annotations_path = f\"{coco_root_dir}/annotations/instances_val2017.json\"\n",
    "coco_val_images = f\"{coco_root_dir}/val2017\"\n",
    "num_img = 1000 # no of images to be evaluated\n",
    "# Load COCO annotations\n",
    "coco_gt = COCO(coco_annotations_path)\n",
    "# Select first n image IDs\n",
    "image_ids = coco_gt.getImgIds()[:num_img] \n",
    "print(f'Selected {len(image_ids)} for evaluation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42884cef",
   "metadata": {},
   "source": [
    "Helper function to calculate IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98f1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two boxes.\n",
    "    Each box is in [x_min, y_min, x_max, y_max] format.\n",
    "    \"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "    return interArea / unionArea if unionArea > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759e958",
   "metadata": {},
   "source": [
    "Defining evaluation function for coco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c82e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_coco_evaluation(coco_gt, image_ids, coco_val_images, image_processor, model):\n",
    "    \"\"\"\n",
    "    Process the selected COCO images with the given model and\n",
    "    calculate both COCO evaluation metrics and simple manual metrics.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    total_inference_time = 0.0\n",
    "    total_detections = 0\n",
    "    total_iou = 0.0\n",
    "    manual_tp, manual_fp, manual_fn = 0, 0, 0\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        # Load image info and file\n",
    "        img_info = coco_gt.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(coco_val_images, img_info['file_name'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Load ground-truth boxes (convert [x, y, w, h] -> [x_min, y_min, x_max, y_max])\n",
    "        ann_ids = coco_gt.getAnnIds(imgIds=img_id)\n",
    "        anns = coco_gt.loadAnns(ann_ids)\n",
    "        gt_boxes = []\n",
    "        for ann in anns:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            gt_boxes.append([x, y, x + w, y + h])\n",
    "        \n",
    "        # Measure inference time\n",
    "        start_time = time.time()\n",
    "        inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        inference_time = time.time() - start_time\n",
    "        total_inference_time += inference_time\n",
    "        \n",
    "        # Post-process outputs (results contains boxes, labels, and scores)\n",
    "        target_sizes = torch.tensor([image.size[::-1]])\n",
    "        results = image_processor.post_process_object_detection(\n",
    "            outputs, threshold=0.9, target_sizes=target_sizes\n",
    "        )[0]\n",
    "        pred_boxes = results[\"boxes\"].tolist()\n",
    "        pred_scores = results[\"scores\"].tolist()\n",
    "        pred_labels = results[\"labels\"].tolist()\n",
    "        \n",
    "        total_detections += len(pred_boxes)\n",
    "        \n",
    "        # Accumulate predictions in COCO format\n",
    "        for bbox, score, label in zip(pred_boxes, pred_scores, pred_labels):\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            predictions.append({\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": int(label),\n",
    "                \"bbox\": [x_min, y_min, width, height],\n",
    "                \"score\": float(score)\n",
    "            })\n",
    "        \n",
    "        # manuallu computing metrics\n",
    "        matched_gt = set()\n",
    "        for bbox, label in zip(pred_boxes, pred_labels):\n",
    "            best_iou = 0\n",
    "            best_gt_idx = -1\n",
    "            for idx, gt_box in enumerate(gt_boxes):\n",
    "                iou = calculate_iou(bbox, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = idx\n",
    "            total_iou += best_iou\n",
    "            if best_iou >= 0.5 and best_gt_idx not in matched_gt:\n",
    "                manual_tp += 1\n",
    "                matched_gt.add(best_gt_idx)\n",
    "            else:\n",
    "                manual_fp += 1\n",
    "        manual_fn += (len(gt_boxes) - len(matched_gt))\n",
    "    \n",
    "\n",
    "    manual_precision = manual_tp / (manual_tp + manual_fp) if (manual_tp + manual_fp) > 0 else 0\n",
    "    manual_recall = manual_tp / (manual_tp + manual_fn) if (manual_tp + manual_fn) > 0 else 0\n",
    "    manual_f1 = (2 * manual_precision * manual_recall / (manual_precision + manual_recall)) if (manual_precision + manual_recall) > 0 else 0\n",
    "    mean_iou = total_iou / total_detections if total_detections > 0 else 0\n",
    "    avg_inference_time = total_inference_time / len(image_ids)\n",
    "    \n",
    "   \n",
    "    if predictions:\n",
    "        coco_dt = coco_gt.loadRes(predictions)\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "        coco_eval.params.imgIds = image_ids \n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        coco_eval.summarize()\n",
    "        mAP = coco_eval.stats[0]  # mAP @[0.5:0.95]\n",
    "        mAR = coco_eval.stats[8]  # mAR \n",
    "    else:\n",
    "        mAP, mAR = 0, 0\n",
    "\n",
    "   \n",
    "    metrics = {\n",
    "        \"mAP\": mAP,\n",
    "        \"mAR\": mAR,\n",
    "        \"Manual Precision\": manual_precision,\n",
    "        \"Manual Recall\": manual_recall,\n",
    "        \"Manual F1 Score\": manual_f1,\n",
    "        \"Mean IoU\": mean_iou,\n",
    "        \"Avg Inference Time per Image\": avg_inference_time\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcf850",
   "metadata": {},
   "source": [
    "Function to evaluate models on coco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6fc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_dir, model_label=\"Model\"):\n",
    "    \"\"\"\n",
    "    Loads the image processor and model from model_dir, runs evaluation,\n",
    "    and prints the results.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_label} from: {model_dir}\")\n",
    "    image_processor = AutoImageProcessor.from_pretrained(model_dir)\n",
    "    model = DetrForObjectDetection.from_pretrained(model_dir)\n",
    "    \n",
    "    metrics = run_coco_evaluation(coco_gt, image_ids, coco_val_images, image_processor, model)\n",
    "    \n",
    "    # Print results in a table format\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Metric\", \"Value\"]\n",
    "    table.add_row([\"COCO mAP (0.5:0.95)\", f\"{metrics['mAP']:.3f}\"])\n",
    "    table.add_row([\"COCO mAR (maxDets=100)\", f\"{metrics['mAR']:.3f}\"])\n",
    "    table.add_row([\"Manual Precision\", f\"{metrics['Manual Precision']:.3f}\"])\n",
    "    table.add_row([\"Manual Recall\", f\"{metrics['Manual Recall']:.3f}\"])\n",
    "    table.add_row([\"Manual F1 Score\", f\"{metrics['Manual F1 Score']:.3f}\"])\n",
    "    table.add_row([\"Mean IoU\", f\"{metrics['Mean IoU']:.3f}\"])\n",
    "    table.add_row([\"Avg Inference Time per Image (s)\", f\"{metrics['Avg Inference Time per Image']:.4f}\"])\n",
    "    print(table)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad37336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file preprocessor_config.json from cache at /home/utn/firi22ka/.cache/huggingface/hub/models--facebook--detr-resnet-50/snapshots/1d5f47bd3bdd2c4bbfa585418ffe6da5028b4c0b/preprocessor_config.json\n",
      "Image processor DetrImageProcessor {\n",
      "  \"do_convert_annotations\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_pad\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"format\": \"coco_detection\",\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"DetrImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"pad_size\": null,\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 1333,\n",
      "    \"shortest_edge\": 800\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Pretrained Model from: facebook/detr-resnet-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/utn/firi22ka/.cache/huggingface/hub/models--facebook--detr-resnet-50/snapshots/1d5f47bd3bdd2c4bbfa585418ffe6da5028b4c0b/config.json\n",
      "Model config DetrConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"DetrForObjectDetection\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auxiliary_loss\": false,\n",
      "  \"backbone\": \"resnet50\",\n",
      "  \"backbone_config\": null,\n",
      "  \"backbone_kwargs\": {\n",
      "    \"in_chans\": 3,\n",
      "    \"out_indices\": [\n",
      "      1,\n",
      "      2,\n",
      "      3,\n",
      "      4\n",
      "    ]\n",
      "  },\n",
      "  \"bbox_cost\": 5,\n",
      "  \"bbox_loss_coefficient\": 5,\n",
      "  \"class_cost\": 1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 256,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"dice_loss_coefficient\": 1,\n",
      "  \"dilation\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_coefficient\": 0.1,\n",
      "  \"giou_cost\": 2,\n",
      "  \"giou_loss_coefficient\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"N/A\",\n",
      "    \"1\": \"person\",\n",
      "    \"2\": \"bicycle\",\n",
      "    \"3\": \"car\",\n",
      "    \"4\": \"motorcycle\",\n",
      "    \"5\": \"airplane\",\n",
      "    \"6\": \"bus\",\n",
      "    \"7\": \"train\",\n",
      "    \"8\": \"truck\",\n",
      "    \"9\": \"boat\",\n",
      "    \"10\": \"traffic light\",\n",
      "    \"11\": \"fire hydrant\",\n",
      "    \"12\": \"street sign\",\n",
      "    \"13\": \"stop sign\",\n",
      "    \"14\": \"parking meter\",\n",
      "    \"15\": \"bench\",\n",
      "    \"16\": \"bird\",\n",
      "    \"17\": \"cat\",\n",
      "    \"18\": \"dog\",\n",
      "    \"19\": \"horse\",\n",
      "    \"20\": \"sheep\",\n",
      "    \"21\": \"cow\",\n",
      "    \"22\": \"elephant\",\n",
      "    \"23\": \"bear\",\n",
      "    \"24\": \"zebra\",\n",
      "    \"25\": \"giraffe\",\n",
      "    \"26\": \"hat\",\n",
      "    \"27\": \"backpack\",\n",
      "    \"28\": \"umbrella\",\n",
      "    \"29\": \"shoe\",\n",
      "    \"30\": \"eye glasses\",\n",
      "    \"31\": \"handbag\",\n",
      "    \"32\": \"tie\",\n",
      "    \"33\": \"suitcase\",\n",
      "    \"34\": \"frisbee\",\n",
      "    \"35\": \"skis\",\n",
      "    \"36\": \"snowboard\",\n",
      "    \"37\": \"sports ball\",\n",
      "    \"38\": \"kite\",\n",
      "    \"39\": \"baseball bat\",\n",
      "    \"40\": \"baseball glove\",\n",
      "    \"41\": \"skateboard\",\n",
      "    \"42\": \"surfboard\",\n",
      "    \"43\": \"tennis racket\",\n",
      "    \"44\": \"bottle\",\n",
      "    \"45\": \"plate\",\n",
      "    \"46\": \"wine glass\",\n",
      "    \"47\": \"cup\",\n",
      "    \"48\": \"fork\",\n",
      "    \"49\": \"knife\",\n",
      "    \"50\": \"spoon\",\n",
      "    \"51\": \"bowl\",\n",
      "    \"52\": \"banana\",\n",
      "    \"53\": \"apple\",\n",
      "    \"54\": \"sandwich\",\n",
      "    \"55\": \"orange\",\n",
      "    \"56\": \"broccoli\",\n",
      "    \"57\": \"carrot\",\n",
      "    \"58\": \"hot dog\",\n",
      "    \"59\": \"pizza\",\n",
      "    \"60\": \"donut\",\n",
      "    \"61\": \"cake\",\n",
      "    \"62\": \"chair\",\n",
      "    \"63\": \"couch\",\n",
      "    \"64\": \"potted plant\",\n",
      "    \"65\": \"bed\",\n",
      "    \"66\": \"mirror\",\n",
      "    \"67\": \"dining table\",\n",
      "    \"68\": \"window\",\n",
      "    \"69\": \"desk\",\n",
      "    \"70\": \"toilet\",\n",
      "    \"71\": \"door\",\n",
      "    \"72\": \"tv\",\n",
      "    \"73\": \"laptop\",\n",
      "    \"74\": \"mouse\",\n",
      "    \"75\": \"remote\",\n",
      "    \"76\": \"keyboard\",\n",
      "    \"77\": \"cell phone\",\n",
      "    \"78\": \"microwave\",\n",
      "    \"79\": \"oven\",\n",
      "    \"80\": \"toaster\",\n",
      "    \"81\": \"sink\",\n",
      "    \"82\": \"refrigerator\",\n",
      "    \"83\": \"blender\",\n",
      "    \"84\": \"book\",\n",
      "    \"85\": \"clock\",\n",
      "    \"86\": \"vase\",\n",
      "    \"87\": \"scissors\",\n",
      "    \"88\": \"teddy bear\",\n",
      "    \"89\": \"hair drier\",\n",
      "    \"90\": \"toothbrush\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"init_xavier_std\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"N/A\": 0,\n",
      "    \"airplane\": 5,\n",
      "    \"apple\": 53,\n",
      "    \"backpack\": 27,\n",
      "    \"banana\": 52,\n",
      "    \"baseball bat\": 39,\n",
      "    \"baseball glove\": 40,\n",
      "    \"bear\": 23,\n",
      "    \"bed\": 65,\n",
      "    \"bench\": 15,\n",
      "    \"bicycle\": 2,\n",
      "    \"bird\": 16,\n",
      "    \"blender\": 83,\n",
      "    \"boat\": 9,\n",
      "    \"book\": 84,\n",
      "    \"bottle\": 44,\n",
      "    \"bowl\": 51,\n",
      "    \"broccoli\": 56,\n",
      "    \"bus\": 6,\n",
      "    \"cake\": 61,\n",
      "    \"car\": 3,\n",
      "    \"carrot\": 57,\n",
      "    \"cat\": 17,\n",
      "    \"cell phone\": 77,\n",
      "    \"chair\": 62,\n",
      "    \"clock\": 85,\n",
      "    \"couch\": 63,\n",
      "    \"cow\": 21,\n",
      "    \"cup\": 47,\n",
      "    \"desk\": 69,\n",
      "    \"dining table\": 67,\n",
      "    \"dog\": 18,\n",
      "    \"donut\": 60,\n",
      "    \"door\": 71,\n",
      "    \"elephant\": 22,\n",
      "    \"eye glasses\": 30,\n",
      "    \"fire hydrant\": 11,\n",
      "    \"fork\": 48,\n",
      "    \"frisbee\": 34,\n",
      "    \"giraffe\": 25,\n",
      "    \"hair drier\": 89,\n",
      "    \"handbag\": 31,\n",
      "    \"hat\": 26,\n",
      "    \"horse\": 19,\n",
      "    \"hot dog\": 58,\n",
      "    \"keyboard\": 76,\n",
      "    \"kite\": 38,\n",
      "    \"knife\": 49,\n",
      "    \"laptop\": 73,\n",
      "    \"microwave\": 78,\n",
      "    \"mirror\": 66,\n",
      "    \"motorcycle\": 4,\n",
      "    \"mouse\": 74,\n",
      "    \"orange\": 55,\n",
      "    \"oven\": 79,\n",
      "    \"parking meter\": 14,\n",
      "    \"person\": 1,\n",
      "    \"pizza\": 59,\n",
      "    \"plate\": 45,\n",
      "    \"potted plant\": 64,\n",
      "    \"refrigerator\": 82,\n",
      "    \"remote\": 75,\n",
      "    \"sandwich\": 54,\n",
      "    \"scissors\": 87,\n",
      "    \"sheep\": 20,\n",
      "    \"shoe\": 29,\n",
      "    \"sink\": 81,\n",
      "    \"skateboard\": 41,\n",
      "    \"skis\": 35,\n",
      "    \"snowboard\": 36,\n",
      "    \"spoon\": 50,\n",
      "    \"sports ball\": 37,\n",
      "    \"stop sign\": 13,\n",
      "    \"street sign\": 12,\n",
      "    \"suitcase\": 33,\n",
      "    \"surfboard\": 42,\n",
      "    \"teddy bear\": 88,\n",
      "    \"tennis racket\": 43,\n",
      "    \"tie\": 32,\n",
      "    \"toaster\": 80,\n",
      "    \"toilet\": 70,\n",
      "    \"toothbrush\": 90,\n",
      "    \"traffic light\": 10,\n",
      "    \"train\": 7,\n",
      "    \"truck\": 8,\n",
      "    \"tv\": 72,\n",
      "    \"umbrella\": 28,\n",
      "    \"vase\": 86,\n",
      "    \"window\": 68,\n",
      "    \"wine glass\": 46,\n",
      "    \"zebra\": 24\n",
      "  },\n",
      "  \"mask_loss_coefficient\": 1,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"detr\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_queries\": 100,\n",
      "  \"position_embedding_type\": \"sine\",\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_pretrained_backbone\": true,\n",
      "  \"use_timm_backbone\": true\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/utn/firi22ka/.cache/huggingface/hub/models--facebook--detr-resnet-50/snapshots/1d5f47bd3bdd2c4bbfa585418ffe6da5028b4c0b/model.safetensors\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DetrForObjectDetection were initialized from the model checkpoint at facebook/detr-resnet-50.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DetrForObjectDetection for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
      "+----------------------------------+--------+\n",
      "|              Metric              | Value  |\n",
      "+----------------------------------+--------+\n",
      "|       COCO mAP (0.5:0.95)        | 0.378  |\n",
      "|      COCO mAR (maxDets=100)      | 0.427  |\n",
      "|         Manual Precision         | 0.761  |\n",
      "|          Manual Recall           | 0.579  |\n",
      "|         Manual F1 Score          | 0.658  |\n",
      "|             Mean IoU             | 0.692  |\n",
      "| Avg Inference Time per Image (s) | 0.5387 |\n",
      "+----------------------------------+--------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': np.float64(0.377783967177354),\n",
       " 'mAR': np.float64(0.426712983865974),\n",
       " 'Manual Precision': 0.7605562150245888,\n",
       " 'Manual Recall': 0.5794573643410853,\n",
       " 'Manual F1 Score': 0.6577693040991421,\n",
       " 'Mean IoU': 0.6920766636999975,\n",
       " 'Avg Inference Time per Image': 0.5387422678470611}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the pretrained model\n",
    "pretrained_dir = \"facebook/detr-resnet-50\"\n",
    "evaluate_model(pretrained_dir, model_label=\"Pretrained Model\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5cba4",
   "metadata": {},
   "source": [
    "# evaluate dert_retrained on coco dataset 10000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935ec492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_10000/preprocessor_config.json\n",
      "Image processor DetrImageProcessor {\n",
      "  \"do_convert_annotations\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_pad\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"format\": \"coco_detection\",\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"DetrImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"pad_size\": null,\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 1333,\n",
      "    \"shortest_edge\": 800\n",
      "  }\n",
      "}\n",
      "\n",
      "loading configuration file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_10000/config.json\n",
      "Model config DetrConfig {\n",
      "  \"_name_or_path\": \"facebook/detr-resnet-50\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"DetrForObjectDetection\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auxiliary_loss\": false,\n",
      "  \"backbone\": \"resnet50\",\n",
      "  \"backbone_config\": null,\n",
      "  \"backbone_kwargs\": {\n",
      "    \"in_chans\": 3,\n",
      "    \"out_indices\": [\n",
      "      1,\n",
      "      2,\n",
      "      3,\n",
      "      4\n",
      "    ]\n",
      "  },\n",
      "  \"bbox_cost\": 5,\n",
      "  \"bbox_loss_coefficient\": 5,\n",
      "  \"class_cost\": 1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 256,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"dice_loss_coefficient\": 1,\n",
      "  \"dilation\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_coefficient\": 0.1,\n",
      "  \"giou_cost\": 2,\n",
      "  \"giou_loss_coefficient\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"N/A\",\n",
      "    \"1\": \"person\",\n",
      "    \"2\": \"bicycle\",\n",
      "    \"3\": \"car\",\n",
      "    \"4\": \"motorcycle\",\n",
      "    \"5\": \"airplane\",\n",
      "    \"6\": \"bus\",\n",
      "    \"7\": \"train\",\n",
      "    \"8\": \"truck\",\n",
      "    \"9\": \"boat\",\n",
      "    \"10\": \"traffic light\",\n",
      "    \"11\": \"fire hydrant\",\n",
      "    \"12\": \"street sign\",\n",
      "    \"13\": \"stop sign\",\n",
      "    \"14\": \"parking meter\",\n",
      "    \"15\": \"bench\",\n",
      "    \"16\": \"bird\",\n",
      "    \"17\": \"cat\",\n",
      "    \"18\": \"dog\",\n",
      "    \"19\": \"horse\",\n",
      "    \"20\": \"sheep\",\n",
      "    \"21\": \"cow\",\n",
      "    \"22\": \"elephant\",\n",
      "    \"23\": \"bear\",\n",
      "    \"24\": \"zebra\",\n",
      "    \"25\": \"giraffe\",\n",
      "    \"26\": \"hat\",\n",
      "    \"27\": \"backpack\",\n",
      "    \"28\": \"umbrella\",\n",
      "    \"29\": \"shoe\",\n",
      "    \"30\": \"eye glasses\",\n",
      "    \"31\": \"handbag\",\n",
      "    \"32\": \"tie\",\n",
      "    \"33\": \"suitcase\",\n",
      "    \"34\": \"frisbee\",\n",
      "    \"35\": \"skis\",\n",
      "    \"36\": \"snowboard\",\n",
      "    \"37\": \"sports ball\",\n",
      "    \"38\": \"kite\",\n",
      "    \"39\": \"baseball bat\",\n",
      "    \"40\": \"baseball glove\",\n",
      "    \"41\": \"skateboard\",\n",
      "    \"42\": \"surfboard\",\n",
      "    \"43\": \"tennis racket\",\n",
      "    \"44\": \"bottle\",\n",
      "    \"45\": \"plate\",\n",
      "    \"46\": \"wine glass\",\n",
      "    \"47\": \"cup\",\n",
      "    \"48\": \"fork\",\n",
      "    \"49\": \"knife\",\n",
      "    \"50\": \"spoon\",\n",
      "    \"51\": \"bowl\",\n",
      "    \"52\": \"banana\",\n",
      "    \"53\": \"apple\",\n",
      "    \"54\": \"sandwich\",\n",
      "    \"55\": \"orange\",\n",
      "    \"56\": \"broccoli\",\n",
      "    \"57\": \"carrot\",\n",
      "    \"58\": \"hot dog\",\n",
      "    \"59\": \"pizza\",\n",
      "    \"60\": \"donut\",\n",
      "    \"61\": \"cake\",\n",
      "    \"62\": \"chair\",\n",
      "    \"63\": \"couch\",\n",
      "    \"64\": \"potted plant\",\n",
      "    \"65\": \"bed\",\n",
      "    \"66\": \"mirror\",\n",
      "    \"67\": \"dining table\",\n",
      "    \"68\": \"window\",\n",
      "    \"69\": \"desk\",\n",
      "    \"70\": \"toilet\",\n",
      "    \"71\": \"door\",\n",
      "    \"72\": \"tv\",\n",
      "    \"73\": \"laptop\",\n",
      "    \"74\": \"mouse\",\n",
      "    \"75\": \"remote\",\n",
      "    \"76\": \"keyboard\",\n",
      "    \"77\": \"cell phone\",\n",
      "    \"78\": \"microwave\",\n",
      "    \"79\": \"oven\",\n",
      "    \"80\": \"toaster\",\n",
      "    \"81\": \"sink\",\n",
      "    \"82\": \"refrigerator\",\n",
      "    \"83\": \"blender\",\n",
      "    \"84\": \"book\",\n",
      "    \"85\": \"clock\",\n",
      "    \"86\": \"vase\",\n",
      "    \"87\": \"scissors\",\n",
      "    \"88\": \"teddy bear\",\n",
      "    \"89\": \"hair drier\",\n",
      "    \"90\": \"toothbrush\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"init_xavier_std\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"N/A\": 0,\n",
      "    \"airplane\": 5,\n",
      "    \"apple\": 53,\n",
      "    \"backpack\": 27,\n",
      "    \"banana\": 52,\n",
      "    \"baseball bat\": 39,\n",
      "    \"baseball glove\": 40,\n",
      "    \"bear\": 23,\n",
      "    \"bed\": 65,\n",
      "    \"bench\": 15,\n",
      "    \"bicycle\": 2,\n",
      "    \"bird\": 16,\n",
      "    \"blender\": 83,\n",
      "    \"boat\": 9,\n",
      "    \"book\": 84,\n",
      "    \"bottle\": 44,\n",
      "    \"bowl\": 51,\n",
      "    \"broccoli\": 56,\n",
      "    \"bus\": 6,\n",
      "    \"cake\": 61,\n",
      "    \"car\": 3,\n",
      "    \"carrot\": 57,\n",
      "    \"cat\": 17,\n",
      "    \"cell phone\": 77,\n",
      "    \"chair\": 62,\n",
      "    \"clock\": 85,\n",
      "    \"couch\": 63,\n",
      "    \"cow\": 21,\n",
      "    \"cup\": 47,\n",
      "    \"desk\": 69,\n",
      "    \"dining table\": 67,\n",
      "    \"dog\": 18,\n",
      "    \"donut\": 60,\n",
      "    \"door\": 71,\n",
      "    \"elephant\": 22,\n",
      "    \"eye glasses\": 30,\n",
      "    \"fire hydrant\": 11,\n",
      "    \"fork\": 48,\n",
      "    \"frisbee\": 34,\n",
      "    \"giraffe\": 25,\n",
      "    \"hair drier\": 89,\n",
      "    \"handbag\": 31,\n",
      "    \"hat\": 26,\n",
      "    \"horse\": 19,\n",
      "    \"hot dog\": 58,\n",
      "    \"keyboard\": 76,\n",
      "    \"kite\": 38,\n",
      "    \"knife\": 49,\n",
      "    \"laptop\": 73,\n",
      "    \"microwave\": 78,\n",
      "    \"mirror\": 66,\n",
      "    \"motorcycle\": 4,\n",
      "    \"mouse\": 74,\n",
      "    \"orange\": 55,\n",
      "    \"oven\": 79,\n",
      "    \"parking meter\": 14,\n",
      "    \"person\": 1,\n",
      "    \"pizza\": 59,\n",
      "    \"plate\": 45,\n",
      "    \"potted plant\": 64,\n",
      "    \"refrigerator\": 82,\n",
      "    \"remote\": 75,\n",
      "    \"sandwich\": 54,\n",
      "    \"scissors\": 87,\n",
      "    \"sheep\": 20,\n",
      "    \"shoe\": 29,\n",
      "    \"sink\": 81,\n",
      "    \"skateboard\": 41,\n",
      "    \"skis\": 35,\n",
      "    \"snowboard\": 36,\n",
      "    \"spoon\": 50,\n",
      "    \"sports ball\": 37,\n",
      "    \"stop sign\": 13,\n",
      "    \"street sign\": 12,\n",
      "    \"suitcase\": 33,\n",
      "    \"surfboard\": 42,\n",
      "    \"teddy bear\": 88,\n",
      "    \"tennis racket\": 43,\n",
      "    \"tie\": 32,\n",
      "    \"toaster\": 80,\n",
      "    \"toilet\": 70,\n",
      "    \"toothbrush\": 90,\n",
      "    \"traffic light\": 10,\n",
      "    \"train\": 7,\n",
      "    \"truck\": 8,\n",
      "    \"tv\": 72,\n",
      "    \"umbrella\": 28,\n",
      "    \"vase\": 86,\n",
      "    \"window\": 68,\n",
      "    \"wine glass\": 46,\n",
      "    \"zebra\": 24\n",
      "  },\n",
      "  \"mask_loss_coefficient\": 1,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"detr\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_queries\": 100,\n",
      "  \"position_embedding_type\": \"sine\",\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_pretrained_backbone\": true,\n",
      "  \"use_timm_backbone\": true\n",
      "}\n",
      "\n",
      "loading weights file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_10000/model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Finetuned Model from: /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DetrForObjectDetection.\n",
      "\n",
      "All the weights of DetrForObjectDetection were initialized from the model checkpoint at /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_10000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DetrForObjectDetection for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.386\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.431\n",
      "+----------------------------------+--------+\n",
      "|              Metric              | Value  |\n",
      "+----------------------------------+--------+\n",
      "|       COCO mAP (0.5:0.95)        | 0.258  |\n",
      "|      COCO mAR (maxDets=100)      | 0.300  |\n",
      "|         Manual Precision         | 0.728  |\n",
      "|          Manual Recall           | 0.452  |\n",
      "|         Manual F1 Score          | 0.558  |\n",
      "|             Mean IoU             | 0.662  |\n",
      "| Avg Inference Time per Image (s) | 0.5581 |\n",
      "+----------------------------------+--------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': np.float64(0.25789124581124223),\n",
       " 'mAR': np.float64(0.2996246568652838),\n",
       " 'Manual Precision': 0.7282948157401624,\n",
       " 'Manual Recall': 0.45193798449612405,\n",
       " 'Manual F1 Score': 0.5577613011241329,\n",
       " 'Mean IoU': 0.6616348767408118,\n",
       " 'Avg Inference Time per Image': 0.5581301186084747}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_dir = \"/home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_10000\"\n",
    "evaluate_model(finetuned_dir, model_label=\"Finetuned Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dc952",
   "metadata": {},
   "source": [
    "# Evaluate on DeTR finetuned on backbone frozen on 100 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb184b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_backobone_freeze_100/preprocessor_config.json\n",
      "Image processor DetrImageProcessor {\n",
      "  \"do_convert_annotations\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_pad\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"format\": \"coco_detection\",\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"DetrImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"pad_size\": null,\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 1333,\n",
      "    \"shortest_edge\": 800\n",
      "  }\n",
      "}\n",
      "\n",
      "loading configuration file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_backobone_freeze_100/config.json\n",
      "Model config DetrConfig {\n",
      "  \"_name_or_path\": \"facebook/detr-resnet-50\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"DetrForObjectDetection\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auxiliary_loss\": false,\n",
      "  \"backbone\": \"resnet50\",\n",
      "  \"backbone_config\": null,\n",
      "  \"backbone_kwargs\": {\n",
      "    \"in_chans\": 3,\n",
      "    \"out_indices\": [\n",
      "      1,\n",
      "      2,\n",
      "      3,\n",
      "      4\n",
      "    ]\n",
      "  },\n",
      "  \"bbox_cost\": 5,\n",
      "  \"bbox_loss_coefficient\": 5,\n",
      "  \"class_cost\": 1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 256,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"dice_loss_coefficient\": 1,\n",
      "  \"dilation\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_coefficient\": 0.1,\n",
      "  \"giou_cost\": 2,\n",
      "  \"giou_loss_coefficient\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"N/A\",\n",
      "    \"1\": \"person\",\n",
      "    \"2\": \"bicycle\",\n",
      "    \"3\": \"car\",\n",
      "    \"4\": \"motorcycle\",\n",
      "    \"5\": \"airplane\",\n",
      "    \"6\": \"bus\",\n",
      "    \"7\": \"train\",\n",
      "    \"8\": \"truck\",\n",
      "    \"9\": \"boat\",\n",
      "    \"10\": \"traffic light\",\n",
      "    \"11\": \"fire hydrant\",\n",
      "    \"12\": \"street sign\",\n",
      "    \"13\": \"stop sign\",\n",
      "    \"14\": \"parking meter\",\n",
      "    \"15\": \"bench\",\n",
      "    \"16\": \"bird\",\n",
      "    \"17\": \"cat\",\n",
      "    \"18\": \"dog\",\n",
      "    \"19\": \"horse\",\n",
      "    \"20\": \"sheep\",\n",
      "    \"21\": \"cow\",\n",
      "    \"22\": \"elephant\",\n",
      "    \"23\": \"bear\",\n",
      "    \"24\": \"zebra\",\n",
      "    \"25\": \"giraffe\",\n",
      "    \"26\": \"hat\",\n",
      "    \"27\": \"backpack\",\n",
      "    \"28\": \"umbrella\",\n",
      "    \"29\": \"shoe\",\n",
      "    \"30\": \"eye glasses\",\n",
      "    \"31\": \"handbag\",\n",
      "    \"32\": \"tie\",\n",
      "    \"33\": \"suitcase\",\n",
      "    \"34\": \"frisbee\",\n",
      "    \"35\": \"skis\",\n",
      "    \"36\": \"snowboard\",\n",
      "    \"37\": \"sports ball\",\n",
      "    \"38\": \"kite\",\n",
      "    \"39\": \"baseball bat\",\n",
      "    \"40\": \"baseball glove\",\n",
      "    \"41\": \"skateboard\",\n",
      "    \"42\": \"surfboard\",\n",
      "    \"43\": \"tennis racket\",\n",
      "    \"44\": \"bottle\",\n",
      "    \"45\": \"plate\",\n",
      "    \"46\": \"wine glass\",\n",
      "    \"47\": \"cup\",\n",
      "    \"48\": \"fork\",\n",
      "    \"49\": \"knife\",\n",
      "    \"50\": \"spoon\",\n",
      "    \"51\": \"bowl\",\n",
      "    \"52\": \"banana\",\n",
      "    \"53\": \"apple\",\n",
      "    \"54\": \"sandwich\",\n",
      "    \"55\": \"orange\",\n",
      "    \"56\": \"broccoli\",\n",
      "    \"57\": \"carrot\",\n",
      "    \"58\": \"hot dog\",\n",
      "    \"59\": \"pizza\",\n",
      "    \"60\": \"donut\",\n",
      "    \"61\": \"cake\",\n",
      "    \"62\": \"chair\",\n",
      "    \"63\": \"couch\",\n",
      "    \"64\": \"potted plant\",\n",
      "    \"65\": \"bed\",\n",
      "    \"66\": \"mirror\",\n",
      "    \"67\": \"dining table\",\n",
      "    \"68\": \"window\",\n",
      "    \"69\": \"desk\",\n",
      "    \"70\": \"toilet\",\n",
      "    \"71\": \"door\",\n",
      "    \"72\": \"tv\",\n",
      "    \"73\": \"laptop\",\n",
      "    \"74\": \"mouse\",\n",
      "    \"75\": \"remote\",\n",
      "    \"76\": \"keyboard\",\n",
      "    \"77\": \"cell phone\",\n",
      "    \"78\": \"microwave\",\n",
      "    \"79\": \"oven\",\n",
      "    \"80\": \"toaster\",\n",
      "    \"81\": \"sink\",\n",
      "    \"82\": \"refrigerator\",\n",
      "    \"83\": \"blender\",\n",
      "    \"84\": \"book\",\n",
      "    \"85\": \"clock\",\n",
      "    \"86\": \"vase\",\n",
      "    \"87\": \"scissors\",\n",
      "    \"88\": \"teddy bear\",\n",
      "    \"89\": \"hair drier\",\n",
      "    \"90\": \"toothbrush\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"init_xavier_std\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"N/A\": 0,\n",
      "    \"airplane\": 5,\n",
      "    \"apple\": 53,\n",
      "    \"backpack\": 27,\n",
      "    \"banana\": 52,\n",
      "    \"baseball bat\": 39,\n",
      "    \"baseball glove\": 40,\n",
      "    \"bear\": 23,\n",
      "    \"bed\": 65,\n",
      "    \"bench\": 15,\n",
      "    \"bicycle\": 2,\n",
      "    \"bird\": 16,\n",
      "    \"blender\": 83,\n",
      "    \"boat\": 9,\n",
      "    \"book\": 84,\n",
      "    \"bottle\": 44,\n",
      "    \"bowl\": 51,\n",
      "    \"broccoli\": 56,\n",
      "    \"bus\": 6,\n",
      "    \"cake\": 61,\n",
      "    \"car\": 3,\n",
      "    \"carrot\": 57,\n",
      "    \"cat\": 17,\n",
      "    \"cell phone\": 77,\n",
      "    \"chair\": 62,\n",
      "    \"clock\": 85,\n",
      "    \"couch\": 63,\n",
      "    \"cow\": 21,\n",
      "    \"cup\": 47,\n",
      "    \"desk\": 69,\n",
      "    \"dining table\": 67,\n",
      "    \"dog\": 18,\n",
      "    \"donut\": 60,\n",
      "    \"door\": 71,\n",
      "    \"elephant\": 22,\n",
      "    \"eye glasses\": 30,\n",
      "    \"fire hydrant\": 11,\n",
      "    \"fork\": 48,\n",
      "    \"frisbee\": 34,\n",
      "    \"giraffe\": 25,\n",
      "    \"hair drier\": 89,\n",
      "    \"handbag\": 31,\n",
      "    \"hat\": 26,\n",
      "    \"horse\": 19,\n",
      "    \"hot dog\": 58,\n",
      "    \"keyboard\": 76,\n",
      "    \"kite\": 38,\n",
      "    \"knife\": 49,\n",
      "    \"laptop\": 73,\n",
      "    \"microwave\": 78,\n",
      "    \"mirror\": 66,\n",
      "    \"motorcycle\": 4,\n",
      "    \"mouse\": 74,\n",
      "    \"orange\": 55,\n",
      "    \"oven\": 79,\n",
      "    \"parking meter\": 14,\n",
      "    \"person\": 1,\n",
      "    \"pizza\": 59,\n",
      "    \"plate\": 45,\n",
      "    \"potted plant\": 64,\n",
      "    \"refrigerator\": 82,\n",
      "    \"remote\": 75,\n",
      "    \"sandwich\": 54,\n",
      "    \"scissors\": 87,\n",
      "    \"sheep\": 20,\n",
      "    \"shoe\": 29,\n",
      "    \"sink\": 81,\n",
      "    \"skateboard\": 41,\n",
      "    \"skis\": 35,\n",
      "    \"snowboard\": 36,\n",
      "    \"spoon\": 50,\n",
      "    \"sports ball\": 37,\n",
      "    \"stop sign\": 13,\n",
      "    \"street sign\": 12,\n",
      "    \"suitcase\": 33,\n",
      "    \"surfboard\": 42,\n",
      "    \"teddy bear\": 88,\n",
      "    \"tennis racket\": 43,\n",
      "    \"tie\": 32,\n",
      "    \"toaster\": 80,\n",
      "    \"toilet\": 70,\n",
      "    \"toothbrush\": 90,\n",
      "    \"traffic light\": 10,\n",
      "    \"train\": 7,\n",
      "    \"truck\": 8,\n",
      "    \"tv\": 72,\n",
      "    \"umbrella\": 28,\n",
      "    \"vase\": 86,\n",
      "    \"window\": 68,\n",
      "    \"wine glass\": 46,\n",
      "    \"zebra\": 24\n",
      "  },\n",
      "  \"mask_loss_coefficient\": 1,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"detr\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_queries\": 100,\n",
      "  \"position_embedding_type\": \"sine\",\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_pretrained_backbone\": true,\n",
      "  \"use_timm_backbone\": true\n",
      "}\n",
      "\n",
      "loading weights file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_backobone_freeze_100/model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Finetuned Model from: /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_backobone_freeze_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DetrForObjectDetection.\n",
      "\n",
      "All the weights of DetrForObjectDetection were initialized from the model checkpoint at /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_backobone_freeze_100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DetrForObjectDetection for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.494\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.557\n",
      "+----------------------------------+--------+\n",
      "|              Metric              | Value  |\n",
      "+----------------------------------+--------+\n",
      "|       COCO mAP (0.5:0.95)        | 0.290  |\n",
      "|      COCO mAR (maxDets=100)      | 0.342  |\n",
      "|         Manual Precision         | 0.681  |\n",
      "|          Manual Recall           | 0.548  |\n",
      "|         Manual F1 Score          | 0.607  |\n",
      "|             Mean IoU             | 0.612  |\n",
      "| Avg Inference Time per Image (s) | 0.5331 |\n",
      "+----------------------------------+--------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': np.float64(0.28998345007148746),\n",
       " 'mAR': np.float64(0.34204071507658573),\n",
       " 'Manual Precision': 0.6810150979762287,\n",
       " 'Manual Recall': 0.5478036175710594,\n",
       " 'Manual F1 Score': 0.6071888872977231,\n",
       " 'Mean IoU': 0.6124405322729614,\n",
       " 'Avg Inference Time per Image': 0.5331497633457184}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_dir = \"/home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco_backobone_freeze_100\"\n",
    "evaluate_model(finetuned_dir, model_label=\"Finetuned Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db41012",
   "metadata": {},
   "source": [
    "# DETR finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec40114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco/preprocessor_config.json\n",
      "Image processor DetrImageProcessor {\n",
      "  \"do_convert_annotations\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_pad\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"format\": \"coco_detection\",\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"DetrImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"pad_size\": null,\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"longest_edge\": 1333,\n",
      "    \"shortest_edge\": 800\n",
      "  }\n",
      "}\n",
      "\n",
      "loading configuration file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco/config.json\n",
      "Model config DetrConfig {\n",
      "  \"_name_or_path\": \"facebook/detr-resnet-50\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"DetrForObjectDetection\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auxiliary_loss\": false,\n",
      "  \"backbone\": \"resnet50\",\n",
      "  \"backbone_config\": null,\n",
      "  \"backbone_kwargs\": {\n",
      "    \"in_chans\": 3,\n",
      "    \"out_indices\": [\n",
      "      1,\n",
      "      2,\n",
      "      3,\n",
      "      4\n",
      "    ]\n",
      "  },\n",
      "  \"bbox_cost\": 5,\n",
      "  \"bbox_loss_coefficient\": 5,\n",
      "  \"class_cost\": 1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 256,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"dice_loss_coefficient\": 1,\n",
      "  \"dilation\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_coefficient\": 0.1,\n",
      "  \"giou_cost\": 2,\n",
      "  \"giou_loss_coefficient\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"N/A\",\n",
      "    \"1\": \"person\",\n",
      "    \"2\": \"bicycle\",\n",
      "    \"3\": \"car\",\n",
      "    \"4\": \"motorcycle\",\n",
      "    \"5\": \"airplane\",\n",
      "    \"6\": \"bus\",\n",
      "    \"7\": \"train\",\n",
      "    \"8\": \"truck\",\n",
      "    \"9\": \"boat\",\n",
      "    \"10\": \"traffic light\",\n",
      "    \"11\": \"fire hydrant\",\n",
      "    \"12\": \"street sign\",\n",
      "    \"13\": \"stop sign\",\n",
      "    \"14\": \"parking meter\",\n",
      "    \"15\": \"bench\",\n",
      "    \"16\": \"bird\",\n",
      "    \"17\": \"cat\",\n",
      "    \"18\": \"dog\",\n",
      "    \"19\": \"horse\",\n",
      "    \"20\": \"sheep\",\n",
      "    \"21\": \"cow\",\n",
      "    \"22\": \"elephant\",\n",
      "    \"23\": \"bear\",\n",
      "    \"24\": \"zebra\",\n",
      "    \"25\": \"giraffe\",\n",
      "    \"26\": \"hat\",\n",
      "    \"27\": \"backpack\",\n",
      "    \"28\": \"umbrella\",\n",
      "    \"29\": \"shoe\",\n",
      "    \"30\": \"eye glasses\",\n",
      "    \"31\": \"handbag\",\n",
      "    \"32\": \"tie\",\n",
      "    \"33\": \"suitcase\",\n",
      "    \"34\": \"frisbee\",\n",
      "    \"35\": \"skis\",\n",
      "    \"36\": \"snowboard\",\n",
      "    \"37\": \"sports ball\",\n",
      "    \"38\": \"kite\",\n",
      "    \"39\": \"baseball bat\",\n",
      "    \"40\": \"baseball glove\",\n",
      "    \"41\": \"skateboard\",\n",
      "    \"42\": \"surfboard\",\n",
      "    \"43\": \"tennis racket\",\n",
      "    \"44\": \"bottle\",\n",
      "    \"45\": \"plate\",\n",
      "    \"46\": \"wine glass\",\n",
      "    \"47\": \"cup\",\n",
      "    \"48\": \"fork\",\n",
      "    \"49\": \"knife\",\n",
      "    \"50\": \"spoon\",\n",
      "    \"51\": \"bowl\",\n",
      "    \"52\": \"banana\",\n",
      "    \"53\": \"apple\",\n",
      "    \"54\": \"sandwich\",\n",
      "    \"55\": \"orange\",\n",
      "    \"56\": \"broccoli\",\n",
      "    \"57\": \"carrot\",\n",
      "    \"58\": \"hot dog\",\n",
      "    \"59\": \"pizza\",\n",
      "    \"60\": \"donut\",\n",
      "    \"61\": \"cake\",\n",
      "    \"62\": \"chair\",\n",
      "    \"63\": \"couch\",\n",
      "    \"64\": \"potted plant\",\n",
      "    \"65\": \"bed\",\n",
      "    \"66\": \"mirror\",\n",
      "    \"67\": \"dining table\",\n",
      "    \"68\": \"window\",\n",
      "    \"69\": \"desk\",\n",
      "    \"70\": \"toilet\",\n",
      "    \"71\": \"door\",\n",
      "    \"72\": \"tv\",\n",
      "    \"73\": \"laptop\",\n",
      "    \"74\": \"mouse\",\n",
      "    \"75\": \"remote\",\n",
      "    \"76\": \"keyboard\",\n",
      "    \"77\": \"cell phone\",\n",
      "    \"78\": \"microwave\",\n",
      "    \"79\": \"oven\",\n",
      "    \"80\": \"toaster\",\n",
      "    \"81\": \"sink\",\n",
      "    \"82\": \"refrigerator\",\n",
      "    \"83\": \"blender\",\n",
      "    \"84\": \"book\",\n",
      "    \"85\": \"clock\",\n",
      "    \"86\": \"vase\",\n",
      "    \"87\": \"scissors\",\n",
      "    \"88\": \"teddy bear\",\n",
      "    \"89\": \"hair drier\",\n",
      "    \"90\": \"toothbrush\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"init_xavier_std\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"N/A\": 0,\n",
      "    \"airplane\": 5,\n",
      "    \"apple\": 53,\n",
      "    \"backpack\": 27,\n",
      "    \"banana\": 52,\n",
      "    \"baseball bat\": 39,\n",
      "    \"baseball glove\": 40,\n",
      "    \"bear\": 23,\n",
      "    \"bed\": 65,\n",
      "    \"bench\": 15,\n",
      "    \"bicycle\": 2,\n",
      "    \"bird\": 16,\n",
      "    \"blender\": 83,\n",
      "    \"boat\": 9,\n",
      "    \"book\": 84,\n",
      "    \"bottle\": 44,\n",
      "    \"bowl\": 51,\n",
      "    \"broccoli\": 56,\n",
      "    \"bus\": 6,\n",
      "    \"cake\": 61,\n",
      "    \"car\": 3,\n",
      "    \"carrot\": 57,\n",
      "    \"cat\": 17,\n",
      "    \"cell phone\": 77,\n",
      "    \"chair\": 62,\n",
      "    \"clock\": 85,\n",
      "    \"couch\": 63,\n",
      "    \"cow\": 21,\n",
      "    \"cup\": 47,\n",
      "    \"desk\": 69,\n",
      "    \"dining table\": 67,\n",
      "    \"dog\": 18,\n",
      "    \"donut\": 60,\n",
      "    \"door\": 71,\n",
      "    \"elephant\": 22,\n",
      "    \"eye glasses\": 30,\n",
      "    \"fire hydrant\": 11,\n",
      "    \"fork\": 48,\n",
      "    \"frisbee\": 34,\n",
      "    \"giraffe\": 25,\n",
      "    \"hair drier\": 89,\n",
      "    \"handbag\": 31,\n",
      "    \"hat\": 26,\n",
      "    \"horse\": 19,\n",
      "    \"hot dog\": 58,\n",
      "    \"keyboard\": 76,\n",
      "    \"kite\": 38,\n",
      "    \"knife\": 49,\n",
      "    \"laptop\": 73,\n",
      "    \"microwave\": 78,\n",
      "    \"mirror\": 66,\n",
      "    \"motorcycle\": 4,\n",
      "    \"mouse\": 74,\n",
      "    \"orange\": 55,\n",
      "    \"oven\": 79,\n",
      "    \"parking meter\": 14,\n",
      "    \"person\": 1,\n",
      "    \"pizza\": 59,\n",
      "    \"plate\": 45,\n",
      "    \"potted plant\": 64,\n",
      "    \"refrigerator\": 82,\n",
      "    \"remote\": 75,\n",
      "    \"sandwich\": 54,\n",
      "    \"scissors\": 87,\n",
      "    \"sheep\": 20,\n",
      "    \"shoe\": 29,\n",
      "    \"sink\": 81,\n",
      "    \"skateboard\": 41,\n",
      "    \"skis\": 35,\n",
      "    \"snowboard\": 36,\n",
      "    \"spoon\": 50,\n",
      "    \"sports ball\": 37,\n",
      "    \"stop sign\": 13,\n",
      "    \"street sign\": 12,\n",
      "    \"suitcase\": 33,\n",
      "    \"surfboard\": 42,\n",
      "    \"teddy bear\": 88,\n",
      "    \"tennis racket\": 43,\n",
      "    \"tie\": 32,\n",
      "    \"toaster\": 80,\n",
      "    \"toilet\": 70,\n",
      "    \"toothbrush\": 90,\n",
      "    \"traffic light\": 10,\n",
      "    \"train\": 7,\n",
      "    \"truck\": 8,\n",
      "    \"tv\": 72,\n",
      "    \"umbrella\": 28,\n",
      "    \"vase\": 86,\n",
      "    \"window\": 68,\n",
      "    \"wine glass\": 46,\n",
      "    \"zebra\": 24\n",
      "  },\n",
      "  \"mask_loss_coefficient\": 1,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"detr\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_queries\": 100,\n",
      "  \"position_embedding_type\": \"sine\",\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_pretrained_backbone\": true,\n",
      "  \"use_timm_backbone\": true\n",
      "}\n",
      "\n",
      "loading weights file /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco/model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Finetuned Model from: /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DetrForObjectDetection.\n",
      "\n",
      "All the weights of DetrForObjectDetection were initialized from the model checkpoint at /home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DetrForObjectDetection for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.26s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.381\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.545\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
      "+----------------------------------+--------+\n",
      "|              Metric              | Value  |\n",
      "+----------------------------------+--------+\n",
      "|       COCO mAP (0.5:0.95)        | 0.353  |\n",
      "|      COCO mAR (maxDets=100)      | 0.402  |\n",
      "|         Manual Precision         | 0.758  |\n",
      "|          Manual Recall           | 0.569  |\n",
      "|         Manual F1 Score          | 0.650  |\n",
      "|             Mean IoU             | 0.681  |\n",
      "| Avg Inference Time per Image (s) | 0.5185 |\n",
      "+----------------------------------+--------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mAP': np.float64(0.3532021516871853),\n",
       " 'mAR': np.float64(0.402203611106347),\n",
       " 'Manual Precision': 0.7578729994837378,\n",
       " 'Manual Recall': 0.5689922480620155,\n",
       " 'Manual F1 Score': 0.6499889307062209,\n",
       " 'Mean IoU': 0.6813058596162751,\n",
       " 'Avg Inference Time per Image': 0.5185170247554779}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_dir = \"/home/utn/firi22ka/Desktop/jenga/mlp/g10/test/detr_finetuned_coco\"\n",
    "evaluate_model(finetuned_dir, model_label=\"Finetuned Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
